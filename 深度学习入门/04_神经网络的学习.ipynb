{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#损失函数\" data-toc-modified-id=\"损失函数-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>损失函数</a></span><ul class=\"toc-item\"><li><span><a href=\"#均方误差\" data-toc-modified-id=\"均方误差-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>均方误差</a></span></li><li><span><a href=\"#交叉熵误差\" data-toc-modified-id=\"交叉熵误差-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>交叉熵误差</a></span></li><li><span><a href=\"#mini-batch学习\" data-toc-modified-id=\"mini-batch学习-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>mini-batch学习</a></span></li></ul></li><li><span><a href=\"#数值微分\" data-toc-modified-id=\"数值微分-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>数值微分</a></span><ul class=\"toc-item\"><li><span><a href=\"#导数\" data-toc-modified-id=\"导数-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>导数</a></span></li><li><span><a href=\"#梯度\" data-toc-modified-id=\"梯度-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>梯度</a></span></li><li><span><a href=\"#梯度下降\" data-toc-modified-id=\"梯度下降-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>梯度下降</a></span></li></ul></li><li><span><a href=\"#两层神经网络实现（SGD）\" data-toc-modified-id=\"两层神经网络实现（SGD）-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>两层神经网络实现（SGD）</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 均方误差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T12:18:59.021862Z",
     "start_time": "2021-01-05T12:18:58.922122Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_square_error(y, t):\n",
    "    return 0.5 * np.sum((y - t) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 交叉熵误差\n",
    "$$ (E = - \\sum\\limits _ { k }  t _ { k } \\log y _ { k }  ) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T12:28:00.234590Z",
     "start_time": "2021-01-05T12:28:00.229768Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## mini-batch学习\n",
    "$$ E = - \\frac { 1 } { N } \\sum\\limits _ { n }\\sum\\limits_{k} t _ { nk} \\log y _ { nk }    $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T12:35:11.762178Z",
     "start_time": "2021-01-05T12:35:11.555541Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"读取数据\"\"\"\n",
    "\n",
    "from dataset.mnist import load_mnist\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(\n",
    "    normalize=True, one_hot_label=True)\n",
    "print(x_train.shape)\n",
    "print(t_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T12:39:40.877470Z",
     "start_time": "2021-01-05T12:39:40.872886Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"随机获取mini_batch\"\"\"\n",
    "\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "\n",
    "x_batch = x_train[batch_mask]\n",
    "y_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T12:52:27.479784Z",
     "start_time": "2021-01-05T12:52:27.475135Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"同时处理多个数据的交叉熵误差\"\"\"\n",
    "\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t * np.log(y + 1e-7)) / batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T12:57:41.200405Z",
     "start_time": "2021-01-05T12:57:41.196114Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"监督数据是标签，one-hot\"\"\"\n",
    "\n",
    "def cross_entropy_error_lable(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T12:59:57.579535Z",
     "start_time": "2021-01-05T12:59:57.577678Z"
    }
   },
   "source": [
    "# 数值微分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 导数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T13:03:06.921621Z",
     "start_time": "2021-01-05T13:03:06.918819Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def mumerical_diff(f, x):\n",
    "    h = 1e-4\n",
    "    return (f(x + h) - f(x - h)) / (2 * h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T13:05:33.840596Z",
     "start_time": "2021-01-05T13:05:33.838384Z"
    }
   },
   "source": [
    "## 梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T13:16:04.329108Z",
     "start_time": "2021-01-05T13:16:04.325457Z"
    }
   },
   "outputs": [],
   "source": [
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T13:10:40.808626Z",
     "start_time": "2021-01-05T13:10:40.806541Z"
    }
   },
   "source": [
    "## 梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T13:16:04.970189Z",
     "start_time": "2021-01-05T13:16:04.966811Z"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr * grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 两层神经网络实现（SGD）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T13:25:14.168954Z",
     "start_time": "2021-01-05T13:25:14.150902Z"
    }
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 为了导入父目录的文件而进行的设定\n",
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        # 初始化权重\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "    \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "        \n",
    "    # x:输入数据, t:监督数据\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    # x:输入数据, t:监督数据\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "    def gradient(self, x, t):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        grads = {}\n",
    "        \n",
    "        batch_num = x.shape[0]\n",
    "        \n",
    "        # forward\n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        # backward\n",
    "        dy = (y - t) / batch_num\n",
    "        grads['W2'] = np.dot(z1.T, dy)\n",
    "        grads['b2'] = np.sum(dy, axis=0)\n",
    "        \n",
    "        da1 = np.dot(dy, W2.T)\n",
    "        dz1 = sigmoid_grad(a1) * da1\n",
    "        grads['W1'] = np.dot(x.T, dz1)\n",
    "        grads['b1'] = np.sum(dz1, axis=0)\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T13:53:56.459145Z",
     "start_time": "2021-01-05T13:53:38.077685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::\t0\t::train acc, test acc | 0.11236666666666667, 0.1135\n",
      ":::\t600\t::train acc, test acc | 0.7900833333333334, 0.7963\n",
      ":::\t1200\t::train acc, test acc | 0.87715, 0.8821\n",
      ":::\t1800\t::train acc, test acc | 0.89795, 0.9021\n",
      ":::\t2400\t::train acc, test acc | 0.9092666666666667, 0.9116\n",
      ":::\t3000\t::train acc, test acc | 0.91525, 0.9193\n",
      ":::\t3600\t::train acc, test acc | 0.9205166666666666, 0.9232\n",
      ":::\t4200\t::train acc, test acc | 0.9230666666666667, 0.9264\n",
      ":::\t4800\t::train acc, test acc | 0.9281166666666667, 0.9297\n",
      ":::\t5400\t::train acc, test acc | 0.9326, 0.9333\n",
      ":::\t6000\t::train acc, test acc | 0.93555, 0.9359\n",
      ":::\t6600\t::train acc, test acc | 0.9374833333333333, 0.9379\n",
      ":::\t7200\t::train acc, test acc | 0.9394333333333333, 0.9396\n",
      ":::\t7800\t::train acc, test acc | 0.9425166666666667, 0.9414\n",
      ":::\t8400\t::train acc, test acc | 0.9446333333333333, 0.9441\n",
      ":::\t9000\t::train acc, test acc | 0.9459, 0.9448\n",
      ":::\t9600\t::train acc, test acc | 0.9469666666666666, 0.9457\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 为了导入父目录的文件而进行的设定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "# 读入数据\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 10000  # 适当设定循环的次数\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 计算梯度\n",
    "#     grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # 更新参数\n",
    "#     print(grad[\"W1\"].shape)\n",
    "    \n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\":::\\t\"+str(i)+\"\\t::train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n",
    "\n",
    "# 绘制图形\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "119px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
